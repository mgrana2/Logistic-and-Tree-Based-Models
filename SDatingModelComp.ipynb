{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speed Dating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8378 entries, 0 to 8377\n",
      "Columns: 123 entries, has_null to match\n",
      "dtypes: float64(59), object(64)\n",
      "memory usage: 7.9+ MB\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('speeddating.csv')\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "has_null: 0.00%\n",
      "wave: 0.00%\n",
      "gender: 0.00%\n",
      "age: 1.13%\n",
      "age_o: 1.24%\n",
      "d_age: 0.00%\n",
      "d_d_age: 0.00%\n",
      "race: 0.00%\n",
      "race_o: 0.00%\n",
      "samerace: 0.00%\n",
      "importance_same_race: 0.94%\n",
      "importance_same_religion: 0.94%\n",
      "d_importance_same_race: 0.00%\n",
      "d_importance_same_religion: 0.00%\n",
      "field: 0.00%\n",
      "pref_o_attractive: 1.06%\n",
      "pref_o_sincere: 1.06%\n",
      "pref_o_intelligence: 1.06%\n",
      "pref_o_funny: 1.17%\n",
      "pref_o_ambitious: 1.28%\n",
      "pref_o_shared_interests: 1.54%\n",
      "d_pref_o_attractive: 0.00%\n",
      "d_pref_o_sincere: 0.00%\n",
      "d_pref_o_intelligence: 0.00%\n",
      "d_pref_o_funny: 0.00%\n",
      "d_pref_o_ambitious: 0.00%\n",
      "d_pref_o_shared_interests: 0.00%\n",
      "attractive_o: 2.53%\n",
      "sinsere_o: 3.43%\n",
      "intelligence_o: 3.65%\n",
      "funny_o: 4.30%\n",
      "ambitous_o: 8.62%\n",
      "shared_interests_o: 12.84%\n",
      "d_attractive_o: 0.00%\n",
      "d_sinsere_o: 0.00%\n",
      "d_intelligence_o: 0.00%\n",
      "d_funny_o: 0.00%\n",
      "d_ambitous_o: 0.00%\n",
      "d_shared_interests_o: 0.00%\n",
      "attractive_important: 0.94%\n",
      "sincere_important: 0.94%\n",
      "intellicence_important: 0.94%\n",
      "funny_important: 1.06%\n",
      "ambtition_important: 1.18%\n",
      "shared_interests_important: 1.44%\n",
      "d_attractive_important: 0.00%\n",
      "d_sincere_important: 0.00%\n",
      "d_intellicence_important: 0.00%\n",
      "d_funny_important: 0.00%\n",
      "d_ambtition_important: 0.00%\n",
      "d_shared_interests_important: 0.00%\n",
      "attractive: 1.25%\n",
      "sincere: 1.25%\n",
      "intelligence: 1.25%\n",
      "funny: 1.25%\n",
      "ambition: 1.25%\n",
      "d_attractive: 0.00%\n",
      "d_sincere: 0.00%\n",
      "d_intelligence: 0.00%\n",
      "d_funny: 0.00%\n",
      "d_ambition: 0.00%\n",
      "attractive_partner: 2.41%\n",
      "sincere_partner: 3.31%\n",
      "intelligence_partner: 3.53%\n",
      "funny_partner: 4.18%\n",
      "ambition_partner: 8.50%\n",
      "shared_interests_partner: 12.74%\n",
      "d_attractive_partner: 0.00%\n",
      "d_sincere_partner: 0.00%\n",
      "d_intelligence_partner: 0.00%\n",
      "d_funny_partner: 0.00%\n",
      "d_ambition_partner: 0.00%\n",
      "d_shared_interests_partner: 0.00%\n",
      "sports: 0.94%\n",
      "tvsports: 0.94%\n",
      "exercise: 0.94%\n",
      "dining: 0.94%\n",
      "museums: 0.94%\n",
      "art: 0.94%\n",
      "hiking: 0.94%\n",
      "gaming: 0.94%\n",
      "clubbing: 0.94%\n",
      "reading: 0.94%\n",
      "tv: 0.94%\n",
      "theater: 0.94%\n",
      "movies: 0.94%\n",
      "concerts: 0.94%\n",
      "music: 0.94%\n",
      "shopping: 0.94%\n",
      "yoga: 0.94%\n",
      "d_sports: 0.00%\n",
      "d_tvsports: 0.00%\n",
      "d_exercise: 0.00%\n",
      "d_dining: 0.00%\n",
      "d_museums: 0.00%\n",
      "d_art: 0.00%\n",
      "d_hiking: 0.00%\n",
      "d_gaming: 0.00%\n",
      "d_clubbing: 0.00%\n",
      "d_reading: 0.00%\n",
      "d_tv: 0.00%\n",
      "d_theater: 0.00%\n",
      "d_movies: 0.00%\n",
      "d_concerts: 0.00%\n",
      "d_music: 0.00%\n",
      "d_shopping: 0.00%\n",
      "d_yoga: 0.00%\n",
      "interests_correlate: 1.89%\n",
      "d_interests_correlate: 0.00%\n",
      "expected_happy_with_sd_people: 1.21%\n",
      "expected_num_interested_in_me: 78.52%\n",
      "expected_num_matches: 14.00%\n",
      "d_expected_happy_with_sd_people: 0.00%\n",
      "d_expected_num_interested_in_me: 0.00%\n",
      "d_expected_num_matches: 0.00%\n",
      "like: 2.86%\n",
      "guess_prob_liked: 3.69%\n",
      "d_like: 0.00%\n",
      "d_guess_prob_liked: 0.00%\n",
      "met: 4.48%\n",
      "decision: 0.00%\n",
      "decision_o: 0.00%\n",
      "match: 0.00%\n"
     ]
    }
   ],
   "source": [
    "null_counts = data.isnull().sum()\n",
    "\n",
    "# calculate the percentage of null values in each column\n",
    "null_percentages = (null_counts / len(data)) * 100\n",
    "\n",
    "# iterate over the null value percentages and print them\n",
    "for col_name, percentage in null_percentages.items():\n",
    "    print(f\"{col_name}: {percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7079 entries, 0 to 8377\n",
      "Columns: 117 entries, has_null to match\n",
      "dtypes: float64(53), object(64)\n",
      "memory usage: 6.4+ MB\n"
     ]
    }
   ],
   "source": [
    "#Columns dropping\n",
    "\n",
    "cols_to_drop = null_percentages[null_percentages > 5].index\n",
    "data = data.drop(cols_to_drop, axis=1)\n",
    "data=data.dropna()\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns: Index(['has_null', 'gender', 'd_d_age', 'race', 'race_o', 'samerace',\n",
      "       'd_importance_same_race', 'd_importance_same_religion', 'field',\n",
      "       'd_pref_o_attractive', 'd_pref_o_sincere', 'd_pref_o_intelligence',\n",
      "       'd_pref_o_funny', 'd_pref_o_ambitious', 'd_pref_o_shared_interests',\n",
      "       'd_attractive_o', 'd_sinsere_o', 'd_intelligence_o', 'd_funny_o',\n",
      "       'd_ambitous_o', 'd_shared_interests_o', 'd_attractive_important',\n",
      "       'd_sincere_important', 'd_intellicence_important', 'd_funny_important',\n",
      "       'd_ambtition_important', 'd_shared_interests_important', 'd_attractive',\n",
      "       'd_sincere', 'd_intelligence', 'd_funny', 'd_ambition',\n",
      "       'd_attractive_partner', 'd_sincere_partner', 'd_intelligence_partner',\n",
      "       'd_funny_partner', 'd_ambition_partner', 'd_shared_interests_partner',\n",
      "       'd_sports', 'd_tvsports', 'd_exercise', 'd_dining', 'd_museums',\n",
      "       'd_art', 'd_hiking', 'd_gaming', 'd_clubbing', 'd_reading', 'd_tv',\n",
      "       'd_theater', 'd_movies', 'd_concerts', 'd_music', 'd_shopping',\n",
      "       'd_yoga', 'd_interests_correlate', 'd_expected_happy_with_sd_people',\n",
      "       'd_expected_num_interested_in_me', 'd_expected_num_matches', 'd_like',\n",
      "       'd_guess_prob_liked', 'decision', 'decision_o', 'match'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Categorical atributes\n",
    "\n",
    "'''\n",
    "All categorical attributes are differences of preferences of\n",
    "previous attributes between self and partner, with the exception of\n",
    "'match' and decisions.\n",
    "'''\n",
    "cat_att = data.select_dtypes(include='object').columns\n",
    "matchAtt = ['match']\n",
    "cat_cols_to_drop = list(set(cat_att) - set(matchAtt))\n",
    "print(f\"Categorical columns: {cat_att}\")\n",
    "data1= data.drop(cat_cols_to_drop, axis=1)\n",
    "data2=data.drop(['decision','decision_o'],axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7079 entries, 0 to 8377\n",
      "Data columns (total 54 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   wave                           7079 non-null   float64\n",
      " 1   age                            7079 non-null   float64\n",
      " 2   age_o                          7079 non-null   float64\n",
      " 3   d_age                          7079 non-null   float64\n",
      " 4   importance_same_race           7079 non-null   float64\n",
      " 5   importance_same_religion       7079 non-null   float64\n",
      " 6   pref_o_attractive              7079 non-null   float64\n",
      " 7   pref_o_sincere                 7079 non-null   float64\n",
      " 8   pref_o_intelligence            7079 non-null   float64\n",
      " 9   pref_o_funny                   7079 non-null   float64\n",
      " 10  pref_o_ambitious               7079 non-null   float64\n",
      " 11  pref_o_shared_interests        7079 non-null   float64\n",
      " 12  attractive_o                   7079 non-null   float64\n",
      " 13  sinsere_o                      7079 non-null   float64\n",
      " 14  intelligence_o                 7079 non-null   float64\n",
      " 15  funny_o                        7079 non-null   float64\n",
      " 16  attractive_important           7079 non-null   float64\n",
      " 17  sincere_important              7079 non-null   float64\n",
      " 18  intellicence_important         7079 non-null   float64\n",
      " 19  funny_important                7079 non-null   float64\n",
      " 20  ambtition_important            7079 non-null   float64\n",
      " 21  shared_interests_important     7079 non-null   float64\n",
      " 22  attractive                     7079 non-null   float64\n",
      " 23  sincere                        7079 non-null   float64\n",
      " 24  intelligence                   7079 non-null   float64\n",
      " 25  funny                          7079 non-null   float64\n",
      " 26  ambition                       7079 non-null   float64\n",
      " 27  attractive_partner             7079 non-null   float64\n",
      " 28  sincere_partner                7079 non-null   float64\n",
      " 29  intelligence_partner           7079 non-null   float64\n",
      " 30  funny_partner                  7079 non-null   float64\n",
      " 31  sports                         7079 non-null   float64\n",
      " 32  tvsports                       7079 non-null   float64\n",
      " 33  exercise                       7079 non-null   float64\n",
      " 34  dining                         7079 non-null   float64\n",
      " 35  museums                        7079 non-null   float64\n",
      " 36  art                            7079 non-null   float64\n",
      " 37  hiking                         7079 non-null   float64\n",
      " 38  gaming                         7079 non-null   float64\n",
      " 39  clubbing                       7079 non-null   float64\n",
      " 40  reading                        7079 non-null   float64\n",
      " 41  tv                             7079 non-null   float64\n",
      " 42  theater                        7079 non-null   float64\n",
      " 43  movies                         7079 non-null   float64\n",
      " 44  concerts                       7079 non-null   float64\n",
      " 45  music                          7079 non-null   float64\n",
      " 46  shopping                       7079 non-null   float64\n",
      " 47  yoga                           7079 non-null   float64\n",
      " 48  interests_correlate            7079 non-null   float64\n",
      " 49  expected_happy_with_sd_people  7079 non-null   float64\n",
      " 50  like                           7079 non-null   float64\n",
      " 51  guess_prob_liked               7079 non-null   float64\n",
      " 52  met                            7079 non-null   float64\n",
      " 53  match                          7079 non-null   int64  \n",
      "dtypes: float64(53), int64(1)\n",
      "memory usage: 3.0 MB\n"
     ]
    }
   ],
   "source": [
    "data1['match'] = data['match'].replace({'b\\'0\\'': 0, 'b\\'1\\'': 1})\n",
    "data1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7079 entries, 0 to 8377\n",
      "Columns: 495 entries, wave to d_funny_b'[9-10]'\n",
      "dtypes: float64(53), object(1), uint8(441)\n",
      "memory usage: 5.9+ MB\n"
     ]
    }
   ],
   "source": [
    "data2 = pd.get_dummies(data, columns=cat_cols_to_drop)\n",
    "data2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Data 1 removes differences columns and decision columns.\n",
    "Data 2 keeps them and uses dummies\n",
    "'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data1\n",
    "\n",
    "X= df[['age', 'attractive']]\n",
    "fullX= df.drop('match', axis=1)\n",
    "y=df['match']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8305084745762712\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logisticModel = LogisticRegression(random_state=16)\n",
    "\n",
    "# fit the model with data\n",
    "logisticModel.fit(X_train, y_train)\n",
    "\n",
    "y_pred = logisticModel.predict(X_test)\n",
    "score = logisticModel.score(X_test, y_test)\n",
    "print(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model scores: [0.82556497 0.82556497 0.82556497 0.82556497 0.82614841]\n",
      "Mean score: 0.8256816593799285\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "logScores = cross_val_score(logisticModel, X, y, cv=5)\n",
    "print(f\"Model scores: {logScores}\")\n",
    "print(f\"Mean score: {logScores.mean()}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree-based models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data1\n",
    "\n",
    "fullX= df.drop('match', axis=1)\n",
    "y=df['match']\n",
    "X_train, X_test, y_train, y_test = train_test_split(fullX, y, test_size=0.25, random_state=0)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.7898305084745763\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(fullX, y, test_size=0.25, random_state=0)\n",
    "\n",
    "treeModel = DecisionTreeClassifier()\n",
    "treeModel.fit(X_train, y_train)\n",
    "y_pred = treeModel.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy score: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model scores: [0.82344633 0.81567797 0.81285311 0.82062147 0.82614841]\n",
      "Mean score: 0.8197494559900982\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation\n",
    "treeScores = cross_val_score(treeModel, X, y, cv=5)\n",
    "print(f\"Model scores: {treeScores}\")\n",
    "print(f\"Mean score: {treeScores.mean()}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.8615819209039548\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "base_estimator = DecisionTreeClassifier()\n",
    "bagging = BaggingClassifier(estimator=base_estimator, n_estimators=100, random_state=0)\n",
    "bagging.fit(X_train, y_train)\n",
    "y_pred = bagging.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy score: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model scores: [0.79237288 0.83474576 0.83898305 0.84110169 0.84240283]\n",
      "Mean score: 0.8299212433371265\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation\n",
    "baggingScore = cross_val_score(bagging, fullX, y, cv=5)\n",
    "print(f\"Model scores: {baggingScore}\")\n",
    "print(f\"Mean score: {baggingScore.mean()}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8587570621468926\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rForest = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rForest.fit(X_train, y_train)\n",
    "y_pred = rForest.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model scores: [0.84251412 0.8460452  0.83403955 0.85169492 0.84028269]\n",
      "Mean score: 0.8429152941646205\n"
     ]
    }
   ],
   "source": [
    "rForestScore = cross_val_score(rForest, fullX, y, cv=5)\n",
    "print(f\"Model scores: {rForestScore}\")\n",
    "print(f\"Mean score: {rForestScore.mean()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "equinox_base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fe5896d181b91c1f459a85a02011a97f6d57380e870963da673668df1c12e6ea"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
